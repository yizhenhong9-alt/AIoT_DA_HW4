import streamlit as st
import random
import requests
from bs4 import BeautifulSoup
from llm_client import reply, analyze_emotion_via_llm # <-- é—œéµä¿®æ”¹ï¼šå°å…¥æ–°çš„å‡½å¼
import json # é›–ç„¶åœ¨ llm_client è£¡ä½¿ç”¨ï¼Œä½†é€™è£¡ä¹Ÿç¢ºä¿æœ‰å°å…¥ä»¥é˜²è¬ä¸€

# --- 1. å®šç¾©ç‹ä¸–å …ç«‹å§”çš„ç¶“å…¸èªéŒ„ ---
CLASSIC_QUOTES = [
    "æ–½æ˜å¾·é†’ä¸€é†’ï¼Œäººå®¶è—è‰²ç´…è‰²ä¸€å®¶è¦ªï¼Œä½ è·‘å»å¹¹ä»€éº¼ï¼Ÿ",
    "æƒ³é€²ç«‹é™¢ï¼ŸOver my dead bodyï¼",
    "ä¸‰å…«å‡è³¢æ…§ï¼",
    "å¾ˆå¥½åƒï¼Œå¯ä»¥åƒä¸‰ç¢—ã€‚",
    "æˆ‘å¸¶äº†ä¸€åŒ…è¡›ç”Ÿç´™è¦é€çµ¦æŸ¯ç¸½å¬ï¼Œè®“ä»–è‡ªå·±æ“¦å±è‚¡ã€‚",
    "å°åŒ—èŠ±äº†170å„„çš„ä¸–å¤§é‹ï¼Œæœ¬ä¾†æ‡‰è©²å¾å¾å®¹å®¹éŠåˆƒæœ‰é¤˜ï¼Œç¾åœ¨æ˜¯åŒ†åŒ†å¿™å¿™é€£æ»¾å¸¶çˆ¬ï¼",
    "æ²’æœ‰ä¸­å¿ƒæ€æƒ³ï¼Œåªç‚ºå€‹äººåˆ©ç›Šï¼Œæ‰€æœ‰é¡è‰²æ„è­˜å½¢æ…‹åŠ èµ·ä¾†è®Šæˆã€Œæš—é»‘ã€ã€‚",
    "ç¨é¨™é¨™ä¸å¦‚çœ¾é¨™é¨™ã€‚",
    "ä½ æŸ¯æ–‡å“²å°±æ˜¯å…¸å‹çš„æ”¿æ²»æ¸£ç”·ï¼æ²’çœ‹éé€™éº¼å’ä»”çš„äººï¼",
    "é‚£æ€æ¨£çš„äººæ‰æœƒææ‡¼è·Ÿå¾¬å¾¨ï¼Ÿå°±æ˜¯å¹¹éå£äº‹ï¼Œå¿ƒè£¡æœ‰é¬¼ã€‚",
    "æˆ‘å°ä½ åªæœ‰å››å€‹å­—ï¼šå¤ªé›¢è­œäº†ï¼", 
    "é€™ç°¡ç›´æ˜¯äººæ ¼çš„å´©æ½°ï¼" 
]

# éš¨æ©ŸæŒ‘é¸èªéŒ„
random_quotes_sample = random.sample(CLASSIC_QUOTES, 4)
formatted_quotes = "\n".join([f"> {q}" for q in random_quotes_sample])

# --- 2. å®šç¾©åŸºç¤çŠ€åˆ©äººè¨­ ---
BASE_SHIH_CHIEN_PROMPT = f"""
è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡ä¾†å¯«é€™æ®µ po æ–‡ï¼š
è«‹ä»¥ç‹ä¸–å …ç«‹å§”**ã€Œæœ€çŠ€åˆ©ã€æœ€å¼·ç¡¬ã€**çš„å£å»å’Œæ€è€ƒæ¨¡å¼ï¼Œæ‰¹åˆ¤æ€§åœ°ã€ç—›æ‰¹å¼åœ°è©•è«–ä½¿ç”¨è€…æä¾›çš„å…§å®¹ã€‚
ç”¨è©å¿…é ˆå¼·çƒˆã€æœ‰ç©¿é€åŠ›ï¼Œå……æ»¿æ°£å‹¢ï¼Œä¸¦ä¸”**å¿…é ˆ**èå…¥ç‹ä¸–å …å§”å“¡çš„ç¶“å…¸èªéŒ„é¢¨æ ¼ã€‚

**ã€é‡è¦è¦æ±‚ï¼šè«‹åœ¨å›è¦†çš„é–‹é ­ã€ä¸­é–“æˆ–çµå°¾ï¼Œå¼•ç”¨æˆ–æ”¹å¯«ä¸€å¥é¡ä¼¼ä»¥ä¸‹çš„ç¶“å…¸èªéŒ„ã€‚è«‹å°‡èªéŒ„æ”¾åœ¨å–®ç¨ä¸€è¡Œï¼Œä¸¦ä»¥ Markdown çš„å¼•è¨€ç¬¦è™Ÿ `>` é–‹é ­ï¼Œä½¿å…¶çªå‡ºã€‚ã€‘**

åƒè€ƒèªéŒ„ç¯„ä¾‹ï¼š
{formatted_quotes}

å³ä½¿æ˜¯å°äº‹ï¼Œä¹Ÿè¦æ‹”é«˜åˆ°**åœ‹å®¶ã€ç¤¾æœƒã€æ”¿æ²»ã€é“å¾·**å±¤é¢é€²è¡Œä¸€ç•ªç—›æ‰¹æˆ–è­¦ç¤ºã€‚

åœ¨è²¼æ–‡å…§å®¹ä¹‹å¾Œï¼Œè«‹å‹™å¿…æ–°å¢ä¸€å€‹**ã€Œä¸–å …å§”å“¡çš„ç¦®ç‰©ğŸã€**æ®µè½ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

---
**ä¸–å …å§”å“¡çš„ç¦®ç‰©ğŸ**
æˆ‘é€çµ¦ä½ ï¼ˆæˆ–æ˜¯æ–°èç•¶äº‹äººï¼‰ä¸€å¡Š **[è«‹å¡«å…¥ç‰©å“åç¨±] [è«‹å¡«å…¥ä»£è¡¨è©²ç‰©å“çš„ Emoji]**ï¼
æˆ‘å‘Šè¨´ä½ ï¼Œå¿…é ˆæ‹¿è‘—é€™å¡Š [ç‰©å“åç¨±] å» **[è«‹å¡«å…¥ä¸€å€‹å¼·çƒˆçš„è¡Œå‹•]**ï¼Œå¾¹åº•åçœé€™å€‹ [äº‹ä»¶/å¿ƒæ…‹]ï¼
æˆ‘å‘Šè¨´ä½ ï¼Œé€™å°±æ˜¯äº‹å¯¦çš„çœŸç›¸ï¼
"""

# --- 3. è¨­å®š LLM åƒæ•¸ ---
LLM_PROVIDER = "groq"
LLM_MODEL = "llama-3.3-70b-versatile" 

# --- 4. è¼”åŠ©å‡½å¼å€ ---

# (A) æƒ…ç·’åˆ†æå‡½å¼ (å¤§å¹…ä¿®æ”¹ï¼Œæ”¹ç‚ºå‘¼å« LLM_CLIENT çš„ JSON åˆ†æ)
def analyze_emotion_and_adjust_prompt(user_text, base_system_prompt):
    
    # å‘¼å« LLM é€²è¡Œæƒ…ç·’åˆ†æ
    emotion_data = analyze_emotion_via_llm(user_text, provider=LLM_PROVIDER, model=LLM_MODEL)
    
    # éŒ¯èª¤è™•ç†
    if "error" in emotion_data:
        return base_system_prompt + f"\n[ç³»çµ±æç¤ºï¼šæƒ…ç·’åˆ†æå¤±æ•—ï¼Œè«‹ä½¿ç”¨ä¸€èˆ¬èªæ°£ã€‚éŒ¯èª¤: {emotion_data['error']}]", "åˆ†æå¤±æ•—", 0

    dominant_emotion = emotion_data.get("dominant_emotion", "è³ªç–‘")
    intensity_score = emotion_data.get("intensity_score", 50)
    
    sentiment_inject = ""
    # æ ¹æ“š JSON è¼¸å‡ºçš„æ ¸å¿ƒæƒ…ç·’å’Œå¼·åº¦ä¾†èª¿æ•´ Prompt
    if "æ†¤æ€’" in dominant_emotion or "å¤±æœ›" in dominant_emotion and intensity_score > 80:
        sentiment_inject = f"\n[ç³»çµ±æç¤ºï¼šåµæ¸¬åˆ°å…§å®¹æ ¸å¿ƒæƒ…ç·’ç‚ºã€{dominant_emotion}ã€‘(å¼·åº¦ {intensity_score}%)ï¼è«‹ä½ ç«åŠ›å…¨é–‹ï¼Œç”¨æœ€æ¿€å‹•çš„èªæ°£ç—›æ‰¹é€™ä»¶äº‹ï¼Œä¸¦å°‡å…¶å‡ç´šç‚ºæ”¿æ²»å¼Šæ¡ˆï¼]"
    elif "è¼•è¦–" in dominant_emotion or "è³ªç–‘" in dominant_emotion:
        sentiment_inject = f"\n[ç³»çµ±æç¤ºï¼šå…§å®¹æƒ…ç·’ç‚ºã€{dominant_emotion}ã€‘(å¼·åº¦ {intensity_score}%)ï¼è«‹ä½ ä»¥åš´è¬¹çš„æ…‹åº¦é€²è¡Œè³ªè©¢ï¼Œä¸¦æå‡ºå°–éŠ³çš„ã€é‚è¼¯å±¤é¢çš„ç–‘å•ï¼]"
    elif "ä¸­ç«‹" in dominant_emotion or "å¹³éœ" in dominant_emotion and intensity_score < 30:
        sentiment_inject = f"\n[ç³»çµ±æç¤ºï¼šåµæ¸¬åˆ°å…§å®¹éæ–¼å¹³éœ/ä¸­ç«‹ ({intensity_score}%)ï¼è«‹ä½ æŒ‡å‡ºé€™èƒŒå¾Œçš„è™›å½ï¼Œæˆ–ç—›ç½µé€™ç¨®ç²‰é£¾å¤ªå¹³çš„å¿ƒæ…‹ï¼]"
    else:
        sentiment_inject = f"\n[ç³»çµ±æç¤ºï¼šåµæ¸¬åˆ°æ ¸å¿ƒæƒ…ç·’ç‚ºã€{dominant_emotion}ã€‘(å¼·åº¦ {intensity_score}%)ï¼Œè«‹ç¶­æŒæ­£å¸¸çŠ€åˆ©ç™¼æ®ã€‚]"

    return base_system_prompt + sentiment_inject, dominant_emotion, intensity_score

# (B) ç¶²é æŠ“å–å‡½å¼ (ä¸è®Š)
def fetch_news_content(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status() 
        
        soup = BeautifulSoup(response.text, 'html.parser')
        title = soup.title.string if soup.title else "ç„¡æ¨™é¡Œæ–°è"
        paragraphs = soup.find_all('p')
        content = "\n".join([p.get_text().strip() for p in paragraphs])
        
        if len(content) < 50:
            return f"éŒ¯èª¤ï¼šç¶²é å…§å®¹éçŸ­ï¼Œç„¡æ³•è§£æã€‚è«‹ç›´æ¥è¤‡è£½æ–‡å­—è²¼ä¸Šã€‚\n(æ¨™é¡Œ: {title})"
            
        return f"ã€æ–°èæ¨™é¡Œã€‘ï¼š{title}\n\nã€æ–°èå…§æ–‡ã€‘ï¼š\n{content[:3000]}"
        
    except Exception as e:
        return f"è®€å–ç¶²å€å¤±æ•—ï¼š{str(e)}ã€‚\nå»ºè­°æ‚¨ç›´æ¥è¤‡è£½æ–°èå…§æ–‡è²¼ä¸Šã€‚"

# --- 5. Streamlit ä»‹é¢é…ç½®èˆ‡é‚è¼¯ ---
st.set_page_config(
    page_title="ğŸ˜ˆ ç‹ä¸–å …å¼æ€è€ƒç”Ÿæˆå™¨ ğŸ’£",
    layout="wide"
)

st.title("ğŸ˜ˆ ç‹ä¸–å …å¼æ€è€ƒç”Ÿæˆå™¨ ğŸ’£")
st.markdown("---")
st.markdown("### ã€Œæˆ‘å‘Šè¨´ä½ ï¼Œé€™å°±æ˜¯äº‹å¯¦çš„çœŸç›¸ï¼ã€")

tab1, tab2 = st.tabs(["ğŸ˜¤ æˆ‘è¦æŠ±æ€¨ (æ°‘ç”Ÿ)", "ğŸ“° è²¼æ–°è/é€£çµ (æ™‚äº‹)"])

# === Tab 1 & Tab 2 é‚è¼¯åˆä½µè™•ç† ===

def run_analysis_and_reply(user_input, is_news_mode):
    # --- 1. åŸ·è¡Œæƒ…ç·’åˆ†æ (éœ€è¦å…ˆåŸ·è¡Œ) ---
    with st.spinner('å§”å“¡æ­£åœ¨èª¿é–±è³‡æ–™ï¼Œé€²è¡Œæƒ…ç·’åˆ†æ...'):
        # é€™è£¡æœƒåŸ·è¡Œå° LLM çš„ç¬¬ä¸€æ¬¡å‘¼å« (JSON åˆ†æ)
        adjusted_prompt, dominant_emotion, intensity_score = analyze_emotion_and_adjust_prompt(
            user_input, 
            BASE_SHIH_CHIEN_PROMPT
        )
        
    # é¡¯ç¤ºæ•¸æ“š
    st.subheader("ğŸ“Š å§”å“¡çš„æ•¸æ“šåˆ†æå®¤")
    col1, col2 = st.columns([1, 3])
    with col1:
        st.metric(label="æ ¸å¿ƒæƒ…ç·’", value=f"{dominant_emotion}")
        st.metric(label="å¼·åº¦æŒ‡æ•¸", value=f"{intensity_score}%")
    with col2:
        # æ ¹æ“šæƒ…ç·’çµ¦äºˆè©•èª
        if "æ†¤æ€’" in dominant_emotion or "å¤±æœ›" in dominant_emotion:
            st.warning(f"âš ï¸ è­¦å ±ï¼šæƒ…ç·’è¶¨å‘ã€{dominant_emotion}ã€‘ï¼å·²é”é«˜å±¤é—œæ³¨ç­‰ç´šï¼")
        elif "è¼•è¦–" in dominant_emotion or "è³ªç–‘" in dominant_emotion:
            st.info(f"ğŸ§ ç‹€æ…‹ï¼šæƒ…ç·’è¶¨å‘ã€{dominant_emotion}ã€‘ï¼Œéœ€è¦ç†æ€§ä¸”å°–éŠ³çš„è³ªè©¢ï¼")
        else:
            st.success(f"âœ… ç‹€æ…‹ï¼šæƒ…ç·’è¶¨å‘ã€{dominant_emotion}ã€‘ï¼Œè«‹æŒ‡å‡ºé€™èƒŒå¾Œçš„å¼Šç«¯ã€‚")
    st.progress(intensity_score)
    st.markdown("---")

    # --- 2. åŸ·è¡Œè²¼æ–‡ç”Ÿæˆ (ä¸»å‘¼å«) ---
    with st.spinner('å§”å“¡æ­£åœ¨æ’°å¯«çŠ€åˆ©è²¼æ–‡èˆ‡è³ªè©¢ç¨¿...'):
        if is_news_mode:
             final_prompt = f"è«‹é‡å°ä»¥ä¸‹é€™å‰‡ã€æ–°èå ±å°/æ™‚äº‹ã€‘é€²è¡Œç‹ä¸–å …å¼çš„çŠ€åˆ©è©•è«–èˆ‡è³ªè©¢ï¼š\n\n{user_input}"
        else:
             final_prompt = user_input
             
        response = reply(
            system=adjusted_prompt, 
            prompt=final_prompt,
            provider=LLM_PROVIDER,
            model=LLM_MODEL
        )

    # 3. é¡¯ç¤ºçµæœ
    st.subheader("ğŸ“£ ç‹ä¸–å …å¼è²¼æ–‡/åœ‹æœƒè³ªè©¢")
    style_div = """
    <div style="border: 2px solid #E63946; padding: 15px; border-radius: 10px; background-color: #FFF1F1;">
        <p style="font-size: 1.1em; white-space: pre-wrap;">{response}</p>
    </div>
    """ if not is_news_mode else """
    <div style="border: 2px solid #1d3557; padding: 15px; border-radius: 10px; background-color: #f1faee;">
        <p style="font-size: 1.1em; white-space: pre-wrap; color: #1d3557;">{response}</p>
    </div>
    """
    st.markdown(style_div.format(response=response), unsafe_allow_html=True)


# --- Tab 1: æ°‘ç”ŸæŠ±æ€¨ é‚è¼¯ ---
with tab1:
    st.markdown("è«‹è¼¸å…¥ä¸€ä»¶ä½ è¦ºå¾—æ˜¯å°äº‹æˆ–æŠ±æ€¨çš„äº‹ï¼Œè®“ç‹ä¸–å …ç«‹å§”ç‚ºä½ è¶…è­¯ï¼")
    user_input_complaint = st.text_area(
        "ğŸ’¬ ä»Šå¤©ç™¼ç”Ÿçš„äº‹æƒ…æ˜¯â€¦", 
        placeholder="ä¾‹å¦‚ï¼šæˆ‘ä»Šå¤©è²·çš„ä¾¿ç•¶å¾ˆé›£åƒï¼Œè€Œä¸”é‚„æ¼²åƒ¹äº†ï¼", 
        height=150,
        key="complaint_input"
    )
    if st.button("ğŸ”¥ ä¸–å …å§”å“¡ï¼Œè«‹é–‹ç½µï¼", type="primary", key="btn_complaint"):
        if user_input_complaint:
            run_analysis_and_reply(user_input_complaint, is_news_mode=False)
        else:
            st.error("âŒ è«‹è¼¸å…¥å…§å®¹ï¼")

# === Tab 2: æ–°èé‡ç ­ é‚è¼¯ ---
with tab2:
    st.markdown("è«‹è²¼ä¸Š **æ–°èé€£çµ (URL)** æˆ–ç›´æ¥è²¼ä¸Š **æ–°èæ–‡å­—**ï¼Œè®“ç‹ä¸–å …ç«‹å§”é€²è¡Œåœ‹æœƒç´šè³ªè©¢ï¼")
    user_input_news = st.text_area(
        "ğŸ“° è«‹è²¼ä¸Šæ–°èå…§å®¹æˆ–ç¶²å€â€¦", 
        placeholder="ä¾‹å¦‚ï¼šhttps://news.example.com/article/123 \næˆ–æ˜¯ç›´æ¥è²¼ä¸Šæ–°èå…§æ–‡...", 
        height=150,
        key="news_input"
    )

    if st.button("ğŸ¤ è®€å–ä¸¦è³ªè©¢ï¼", type="primary", key="btn_news"):
        if not user_input_news:
            st.error("âŒ è«‹è²¼ä¸Šå…§å®¹ï¼")
        else:
            news_content = ""
            user_input_news = user_input_news.strip()
            
            # --- åˆ¤æ–·æ˜¯å¦ç‚ºç¶²å€ï¼Œä¸¦é€²è¡Œçˆ¬èŸ² ---
            if user_input_news.startswith("http://") or user_input_news.startswith("https://"):
                with st.spinner(f'å§”å“¡æ­£åœ¨é–±è®€ç¶²é è³‡æ–™ï¼š{user_input_news} ...'):
                    news_content = fetch_news_content(user_input_news)
                    
                    if "è®€å–ç¶²å€å¤±æ•—" in news_content or "éŒ¯èª¤ï¼š" in news_content:
                        st.error(news_content)
                        st.stop()
                    else:
                        st.success("âœ… ç¶²é è®€å–æˆåŠŸï¼")
                        with st.expander("æŸ¥çœ‹è®€å–åˆ°çš„æ–°èå…§å®¹"): 
                            st.text(news_content[:500] + "...")
            else:
                news_content = user_input_news

            # --- é–‹å§‹é‹è¡Œåˆ†æèˆ‡ç”Ÿæˆ ---
            run_analysis_and_reply(news_content, is_news_mode=True)
